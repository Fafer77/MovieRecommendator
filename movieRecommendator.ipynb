{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "594d11e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import optuna\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f23377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Used device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acfca32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"movies_dataset.csv\")\n",
    "x = df[[\"user_id\", \"movie_id\"]]\n",
    "y = df[\"rating\"]\n",
    "\n",
    "X_f, X_test, y_f, y_test = train_test_split(\n",
    "    x, y, test_size=0.15, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_f, y_f, test_size=0.12, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74df7c3",
   "metadata": {},
   "source": [
    "### Baseline - average of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44b21cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings average global: 3.50\n",
      "Baseline mse: 1.1329\n"
     ]
    }
   ],
   "source": [
    "average_rating = df[\"rating\"].mean()\n",
    "y_pred_baseline = [average_rating] * len(y_test)\n",
    "baseline_mse = mean_squared_error(y_test, y_pred_baseline)\n",
    "\n",
    "print(f\"Ratings average global: {average_rating:.2f}\")\n",
    "print(f\"Baseline mse: {baseline_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec16bb6",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bbd02c",
   "metadata": {},
   "source": [
    "using pytorch Dataset to create custom dataset for neural network and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d306421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, df, targets):\n",
    "        self.users = torch.tensor(df[\"user_id\"].values, dtype=torch.long)\n",
    "        self.movies = torch.tensor(df[\"movie_id\"].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(targets.values, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.users[index], self.movies[index], self.ratings[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c703a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MovieDataset(X_train, y_train)\n",
    "valid_set = MovieDataset(X_valid, y_valid)\n",
    "test_set = MovieDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08a42850",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295c79dc",
   "metadata": {},
   "source": [
    "Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7094ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, embedding_dim=32, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.movie_embedding = nn.Embedding(n_movies, embedding_dim)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        self.user_embedding.weight.data.uniform_(0, 0.05)\n",
    "        self.movie_embedding.weight.data.uniform_(0, 0.05)\n",
    "    \n",
    "    def forward(self, user, movie):\n",
    "        user_vector = self.user_embedding(user)\n",
    "        movie_vector = self.movie_embedding(movie)\n",
    "        x = torch.cat([user_vector, movie_vector], dim=-1)\n",
    "\n",
    "        return self.mlp(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dcc9890",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = df['user_id'].nunique()\n",
    "n_movies = df['movie_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fc61eb",
   "metadata": {},
   "source": [
    "train model and find hyperparameters using optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "341fa68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    emb_dim = trial.suggest_categorical(\"embedding_dim\", [16, 32, 64])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.2, 0.5)\n",
    "\n",
    "    model = Recommender(n_users, n_movies, emb_dim, dropout).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    n_epochs = 5\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for users, movies, ratings in train_loader:\n",
    "            users, movies, ratings = users.to(device), movies.to(device), ratings.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(users, movies)\n",
    "            loss = criterion(pred, ratings)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        valid_mse = 0\n",
    "        with torch.inference_mode():\n",
    "            for users, movies, ratings in valid_loader:\n",
    "                users, movies, ratings = users.to(device), movies.to(device), ratings.to(device)\n",
    "                preds = model(users, movies)\n",
    "                valid_mse += criterion(preds, ratings).item()\n",
    "        \n",
    "        avg_valid_mse = valid_mse / len(valid_loader)\n",
    "\n",
    "        trial.report(avg_valid_mse, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    \n",
    "    return avg_valid_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1222b90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-28 11:05:39,189] A new study created in memory with name: no-name-0160c46a-522e-4b42-97ea-69ead40c57fb\n",
      "[I 2026-01-28 11:06:11,439] Trial 0 finished with value: 0.8687361645698547 and parameters: {'embedding_dim': 32, 'lr': 0.0015751320499779737, 'dropout': 0.24680559213273096}. Best is trial 0 with value: 0.8687361645698547.\n",
      "[I 2026-01-28 11:06:47,006] Trial 1 finished with value: 0.8247564500570297 and parameters: {'embedding_dim': 64, 'lr': 0.0015930522616241021, 'dropout': 0.41242177333881364}. Best is trial 1 with value: 0.8247564500570297.\n",
      "[I 2026-01-28 11:07:16,876] Trial 2 finished with value: 0.8555025804042816 and parameters: {'embedding_dim': 32, 'lr': 0.00026587543983272726, 'dropout': 0.2545474901621302}. Best is trial 1 with value: 0.8247564500570297.\n",
      "[I 2026-01-28 11:07:52,628] Trial 3 finished with value: 0.8752407956123353 and parameters: {'embedding_dim': 64, 'lr': 0.0007309539835912913, 'dropout': 0.2873687420594126}. Best is trial 1 with value: 0.8247564500570297.\n",
      "[I 2026-01-28 11:08:21,176] Trial 4 finished with value: 0.8418091768026352 and parameters: {'embedding_dim': 16, 'lr': 0.0005404103854647331, 'dropout': 0.3368209952651108}. Best is trial 1 with value: 0.8247564500570297.\n",
      "[I 2026-01-28 11:08:26,889] Trial 5 pruned. \n",
      "[I 2026-01-28 11:08:55,845] Trial 6 finished with value: 0.8128783911466598 and parameters: {'embedding_dim': 16, 'lr': 0.007902619549708232, 'dropout': 0.4896896099223678}. Best is trial 6 with value: 0.8128783911466598.\n",
      "[I 2026-01-28 11:09:24,807] Trial 7 finished with value: 0.8417828011512757 and parameters: {'embedding_dim': 16, 'lr': 0.0023359635026261607, 'dropout': 0.3320457481218804}. Best is trial 6 with value: 0.8128783911466598.\n",
      "[I 2026-01-28 11:09:53,489] Trial 8 finished with value: 0.8487953507900238 and parameters: {'embedding_dim': 32, 'lr': 0.006586289317583112, 'dropout': 0.2776339944800051}. Best is trial 6 with value: 0.8128783911466598.\n",
      "[I 2026-01-28 11:09:59,691] Trial 9 pruned. \n",
      "[I 2026-01-28 11:10:31,773] Trial 10 finished with value: 0.8103295028209686 and parameters: {'embedding_dim': 16, 'lr': 0.007340778207430317, 'dropout': 0.4908611332363598}. Best is trial 10 with value: 0.8103295028209686.\n",
      "[I 2026-01-28 11:11:03,335] Trial 11 finished with value: 0.8163481342792511 and parameters: {'embedding_dim': 16, 'lr': 0.009550165044129548, 'dropout': 0.480286692442406}. Best is trial 10 with value: 0.8103295028209686.\n",
      "[I 2026-01-28 11:11:09,433] Trial 12 pruned. \n",
      "[I 2026-01-28 11:11:15,670] Trial 13 pruned. \n",
      "[I 2026-01-28 11:11:45,849] Trial 14 finished with value: 0.8223960262537002 and parameters: {'embedding_dim': 16, 'lr': 0.009772246159786144, 'dropout': 0.4255439972231595}. Best is trial 10 with value: 0.8103295028209686.\n",
      "[I 2026-01-28 11:12:24,051] Trial 15 finished with value: 0.8355820375680924 and parameters: {'embedding_dim': 64, 'lr': 0.0033483131954407603, 'dropout': 0.3867839472407674}. Best is trial 10 with value: 0.8103295028209686.\n",
      "[I 2026-01-28 11:12:30,119] Trial 16 pruned. \n",
      "[I 2026-01-28 11:13:00,937] Trial 17 finished with value: 0.8289734768867493 and parameters: {'embedding_dim': 16, 'lr': 0.005517056553808934, 'dropout': 0.4615462369688979}. Best is trial 10 with value: 0.8103295028209686.\n",
      "[I 2026-01-28 11:13:15,939] Trial 18 pruned. \n",
      "[I 2026-01-28 11:13:28,133] Trial 19 pruned. \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    sampler=sampler,\n",
    "    pruner=optuna.pruners.MedianPruner()\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912cf9fd",
   "metadata": {},
   "source": [
    "### Train model more thouroughly on the best params found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89fe3d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model function\n",
    "\n",
    "def evaluate_tm(model, data_loader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.inference_mode():\n",
    "        for users, movies, ratings in data_loader:\n",
    "            users, movies, ratings = users.to(device), movies.to(device), ratings.to(device)\n",
    "            y_pred = model(users, movies)\n",
    "            loss = loss_fn(y_pred, ratings)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be6bbb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "\n",
    "def train_with_early_stopping(model, optimizer, loss_fn, train_loader,\n",
    "                              valid_loader, n_epochs, patience=10):\n",
    "    history = {\"train_losses\": [], \"valid_losses\": []}\n",
    "    best_valid_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.0\n",
    "        model.train()\n",
    "        t0 = time.time()\n",
    "\n",
    "        for users, movies, ratings in train_loader:\n",
    "            users, movies, ratings = users.to(device), movies.to(device), ratings.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(users, movies)\n",
    "            loss = loss_fn(y_pred, ratings)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        avg_valid_loss = evaluate_tm(model, valid_loader, loss_fn)\n",
    "\n",
    "        if avg_valid_loss < best_valid_loss:\n",
    "            best_valid_loss = avg_valid_loss\n",
    "            torch.save(model.state_dict(), \"best_model_tmp.pth\")\n",
    "            best = \" (best)\"\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            best = \"\"\n",
    "        \n",
    "        t1 = time.time()\n",
    "        history[\"train_losses\"].append(avg_train_loss)\n",
    "        history[\"valid_losses\"].append(avg_valid_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs} | \"\n",
    "              f\"Train MSE: {avg_train_loss:.4f} | \"\n",
    "              f\"Valid MSE: {avg_valid_loss:.4f}{best} | \"\n",
    "              f\"Time: {t1 - t0:.1f}s\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            model.load_state_dict(torch.load(\"best_model_tmp.pth\"))\n",
    "            break\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f4a956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_valid_loss(history):\n",
    "    epochs = range(1, len(history[\"train_losse\"]) + 1)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(epochs, history[\"train_losses\"], \"bo-\", label=\"training\")\n",
    "    plt.plot(epochs, history[\"valid_losses\"], \"ro-\", label=\"validation\")\n",
    "\n",
    "    plt.title(\"Training vs validation loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss value\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d52d2509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best learning rate: 0.007340778207430317\n",
      "Best dropout: 0.4908611332363598\n",
      "Best embedding dimension: 16\n"
     ]
    }
   ],
   "source": [
    "params = study.best_params\n",
    "\n",
    "print(f\"Best learning rate: {params['lr']}\")\n",
    "print(f\"Best dropout: {params['dropout']}\")\n",
    "print(f\"Best embedding dimension: {params['embedding_dim']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f412dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_recommender = Recommender(\n",
    "    n_users, n_movies,\n",
    "    embedding_dim=64,\n",
    "    dropout_rate=0.3\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(final_recommender.parameters(), lr=params[\"lr\"])\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb3f0513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train MSE: 1.0977 | Valid MSE: 0.8369 (best) | Time: 12.0s\n",
      "Epoch 2/100 | Train MSE: 0.7990 | Valid MSE: 0.8174 (best) | Time: 11.8s\n",
      "Epoch 3/100 | Train MSE: 0.7062 | Valid MSE: 0.8106 (best) | Time: 11.8s\n",
      "Epoch 4/100 | Train MSE: 0.6412 | Valid MSE: 0.8232 | Time: 11.8s\n",
      "Epoch 5/100 | Train MSE: 0.5819 | Valid MSE: 0.8413 | Time: 11.5s\n",
      "Epoch 6/100 | Train MSE: 0.5237 | Valid MSE: 0.8603 | Time: 11.8s\n",
      "Epoch 7/100 | Train MSE: 0.4736 | Valid MSE: 0.8585 | Time: 11.8s\n",
      "Epoch 8/100 | Train MSE: 0.4330 | Valid MSE: 0.8949 | Time: 11.8s\n",
      "Epoch 9/100 | Train MSE: 0.3974 | Valid MSE: 0.9012 | Time: 11.8s\n",
      "Epoch 10/100 | Train MSE: 0.3700 | Valid MSE: 0.8971 | Time: 11.9s\n",
      "Epoch 11/100 | Train MSE: 0.3455 | Valid MSE: 0.9558 | Time: 11.7s\n",
      "Epoch 12/100 | Train MSE: 0.3275 | Valid MSE: 0.9403 | Time: 11.8s\n",
      "Epoch 13/100 | Train MSE: 0.3109 | Valid MSE: 0.9436 | Time: 11.9s\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9w/pb6mlr6d24s06b6lfpymf__80000gn/T/ipykernel_75876/2185236908.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model_tmp.pth\"))\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "n_epochs = 100\n",
    "history = train_with_early_stopping(\n",
    "    final_recommender, \n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    n_epochs,\n",
    "    patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea14dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
